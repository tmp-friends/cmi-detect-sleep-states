{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed8db51",
   "metadata": {
    "papermill": {
     "duration": 0.006532,
     "end_time": "2023-11-18T05:19:59.729609",
     "exception": false,
     "start_time": "2023-11-18T05:19:59.723077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CMI Detect Sleep States - Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e665c269",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-18T05:19:59.743400Z",
     "iopub.status.busy": "2023-11-18T05:19:59.743009Z",
     "iopub.status.idle": "2023-11-18T05:20:00.670891Z",
     "shell.execute_reply": "2023-11-18T05:20:00.668771Z"
    },
    "papermill": {
     "duration": 0.93789,
     "end_time": "2023-11-18T05:20:00.673667",
     "exception": false,
     "start_time": "2023-11-18T05:19:59.735777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cmi-deep-sleep-states-train/model_best.pth\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378d52e3",
   "metadata": {
    "papermill": {
     "duration": 0.005922,
     "end_time": "2023-11-18T05:20:00.685909",
     "exception": false,
     "start_time": "2023-11-18T05:20:00.679987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3f07b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T05:20:00.701592Z",
     "iopub.status.busy": "2023-11-18T05:20:00.700168Z",
     "iopub.status.idle": "2023-11-18T05:20:08.126302Z",
     "shell.execute_reply": "2023-11-18T05:20:08.125341Z"
    },
    "papermill": {
     "duration": 7.436415,
     "end_time": "2023-11-18T05:20:08.129012",
     "exception": false,
     "start_time": "2023-11-18T05:20:00.692597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import math\n",
    "from math import pi, sqrt, exp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "import sklearn, sklearn.model_selection\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa\n",
    "import ctypes\n",
    "\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b98db70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T05:20:08.144859Z",
     "iopub.status.busy": "2023-11-18T05:20:08.144432Z",
     "iopub.status.idle": "2023-11-18T05:20:08.151426Z",
     "shell.execute_reply": "2023-11-18T05:20:08.150484Z"
    },
    "papermill": {
     "duration": 0.018066,
     "end_time": "2023-11-18T05:20:08.154128",
     "exception": false,
     "start_time": "2023-11-18T05:20:08.136062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PATHS:\n",
    "    MAIN_DIR = \"/kaggle/input/child-mind-institute-detect-sleep-states/\"\n",
    "    # csv files :\n",
    "    SUBMISSION = MAIN_DIR + \"sample_submission.csv\"\n",
    "    TRAIN_EVENTS = MAIN_DIR + \"train_events.csv\"\n",
    "    \n",
    "    # parquet files:\n",
    "    TRAIN_SERIES = MAIN_DIR + \"train_series.parquet\"\n",
    "    TEST_SERIES = MAIN_DIR + \"test_series.parquet\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57640b29",
   "metadata": {
    "papermill": {
     "duration": 0.006705,
     "end_time": "2023-11-18T05:20:08.167951",
     "exception": false,
     "start_time": "2023-11-18T05:20:08.161246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1fa6408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T05:20:08.183736Z",
     "iopub.status.busy": "2023-11-18T05:20:08.183310Z",
     "iopub.status.idle": "2023-11-18T05:20:08.210027Z",
     "shell.execute_reply": "2023-11-18T05:20:08.209004Z"
    },
    "papermill": {
     "duration": 0.038184,
     "end_time": "2023-11-18T05:20:08.213108",
     "exception": false,
     "start_time": "2023-11-18T05:20:08.174924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataReader:\n",
    "    def __init__(self, demo_mode):\n",
    "        super().__init__()\n",
    "        \n",
    "        # mapping for data loading\n",
    "        self.names_mapping = {\n",
    "            \"submission\": {\n",
    "                \"path\": PATHS.SUBMISSION,\n",
    "                \"is_parquet\": False,\n",
    "                \"has_timestamp\": False,\n",
    "            },\n",
    "            \"train_events\": {\n",
    "                \"path\": PATHS.TRAIN_EVENTS,\n",
    "                \"is_parquet\": False,\n",
    "                \"has_timestamp\": True,\n",
    "            },\n",
    "            \"train_series\": {\n",
    "                \"path\": PATHS.TRAIN_SERIES,\n",
    "                \"is_parquet\": True,\n",
    "                \"has_timestamp\": True,\n",
    "            },\n",
    "            \"test_series\": {\n",
    "                \"path\": PATHS.TEST_SERIES,\n",
    "                \"is_parquet\": True,\n",
    "                \"has_timestamp\": True,\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        self.valid_names = [\n",
    "            \"submission\",\n",
    "            \"train_events\",\n",
    "            \"train_series\",\n",
    "            \"test_series\",\n",
    "        ]\n",
    "        \n",
    "        self.demo_mode = demo_mode\n",
    "    \n",
    "    def verify(self, data_name):\n",
    "        \"\"\"変数名のバリデーション\"\"\"\n",
    "        if data_name not in self.valid_names:\n",
    "            print(\"PLEASE ENTER A VALID DATASET NAME, VALID NAMES ARE: \", valid_names)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def cleaning(self, data):\n",
    "        \"\"\"drop na values\"\"\"\n",
    "        before_cleaning = len(data)\n",
    "        print(\"Number of missing timestamps: \", len(data[data[\"timestamp\"].isna()]))\n",
    "        \n",
    "        data = data.dropna(subset=[\"timestamp\"])\n",
    "        after_cleaning = len(data)\n",
    "        \n",
    "        print(\n",
    "            \"Percentage of removed rows: {:.1f}%\".format(\n",
    "                100*(before_cleaning - after_cleaning) / before_cleaning\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def reduce_memory_usage(data):\n",
    "        \"\"\"iterate through all the columns of a dataframe and modify the data type to reduce memory usage\"\"\"\n",
    "        start_mem = data.memory_usage().sum() / 1024**2\n",
    "        print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "        \n",
    "        for col in data.columns:\n",
    "            col_type = data[col].dtype\n",
    "            if col_type != object:\n",
    "                c_min = data[col].min()\n",
    "                c_max = data[col].max()\n",
    "                \n",
    "                # 型によってメモリサイズを最適化\n",
    "                if str(col_type)[:3] == \"int\":\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        data[col] = data[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        data[col] = data[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        data[col] = data[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        data[col] = data[col].astype(np.int64)\n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        data[col] = data[col].astype(np.float16)\n",
    "                    elif c_min > np.iinfo(np.float32).min and c_max < np.iinfo(np.float32).max:\n",
    "                        data[col] = data[col].astype(np.float32)\n",
    "                    else:\n",
    "                        data[col] = data[col].astype(np.float64)\n",
    "            else:\n",
    "                data[col] = data[col].astype(\"category\")\n",
    "        \n",
    "        end_mem = data.memory_usage().sum() / 1024**2\n",
    "        \n",
    "        print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "        print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def load_data(self, data_name):\n",
    "        \"\"\"データのロード\"\"\"\n",
    "        self.verify(data_name)\n",
    "        data_props = self.names_mapping[data_name]\n",
    "        \n",
    "        if data_props[\"is_parquet\"]:\n",
    "            if self.demo_mode:\n",
    "                pf = ParquetFile(data_props[\"path\"])\n",
    "                demo_rows = next(pf.iter_batches(batch_size=20_000))\n",
    "                data = pa.Table.from_batches([demo_rows]).to_pandas()\n",
    "            else:\n",
    "                data = pd.read_parquet(data_props[\"path\"])\n",
    "        else:\n",
    "            if self.demo_mode:\n",
    "                data = pd.read_csv(data_props[\"path\"], nrows=20_000)\n",
    "            else:\n",
    "                data = pd.read_csv(data_props[\"path\"])\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        if data_props[\"has_timestamp\"]:\n",
    "            print(\"cleaning\")\n",
    "            data = self.cleaning(data)\n",
    "            \n",
    "            gc.collect()\n",
    "        \n",
    "        data = self.reduce_memory_usage(data)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f631f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T05:20:08.227290Z",
     "iopub.status.busy": "2023-11-18T05:20:08.226868Z",
     "iopub.status.idle": "2023-11-18T05:20:08.909788Z",
     "shell.execute_reply": "2023-11-18T05:20:08.908529Z"
    },
    "papermill": {
     "duration": 0.692836,
     "end_time": "2023-11-18T05:20:08.912231",
     "exception": false,
     "start_time": "2023-11-18T05:20:08.219395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning\n",
      "Number of missing timestamps:  0\n",
      "Percentage of removed rows: 0.0%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by -92.2%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = DataReader(demo_mode=False)\n",
    "test_series = reader.load_data(data_name=\"test_series\")\n",
    "ids = test_series.series_id.unique()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ee7a14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T05:20:08.927044Z",
     "iopub.status.busy": "2023-11-18T05:20:08.926620Z",
     "iopub.status.idle": "2023-11-18T05:20:09.139591Z",
     "shell.execute_reply": "2023-11-18T05:20:09.138431Z"
    },
    "papermill": {
     "duration": 0.224335,
     "end_time": "2023-11-18T05:20:09.143094",
     "exception": false,
     "start_time": "2023-11-18T05:20:08.918759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488e7f1302854a339f808343c8604615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIGMA = 720\n",
    "SAMPLE_FREQ = 12\n",
    "\n",
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, series_ids, series):\n",
    "        series = series.reset_index()\n",
    "        self.data = []\n",
    "        \n",
    "        for viz_id in tqdm(series_ids):\n",
    "            self.data.append(series.loc[(series.series_id==viz_id)].copy().reset_index())\n",
    "    \n",
    "    def downsample_seq_generate_features(self, feat, downsample_factor=SAMPLE_FREQ):\n",
    "        if len(feat) % SAMPLE_FREQ != 0:\n",
    "            feat = np.concatenate([feat, np.zeros(SAMPLE_FREQ - len(feat) % SAMPLE_FREQ)+feat[-1]])\n",
    "        \n",
    "        # generate seq\n",
    "        feat = np.reshape(feat, (-1, SAMPLE_FREQ))\n",
    "        feat_mean = np.mean(feat, 1)\n",
    "        feat_std = np.std(feat, 1)\n",
    "        feat_median = np.median(feat, 1)\n",
    "        feat_max = np.max(feat, 1)\n",
    "        feat_min = np.min(feat, 1)\n",
    "        \n",
    "        return np.dstack([feat_mean, feat_std, feat_median, feat_max, feat_min])[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx][[\"anglez\", \"enmo\"]].values.astype(np.float32)\n",
    "        \n",
    "        X = np.concatenate(\n",
    "            [\n",
    "                self.downsample_seq_generate_features(\n",
    "                    X[:,i],\n",
    "                    SAMPLE_FREQ,\n",
    "                ) for i in range(X.shape[1])\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        \n",
    "        X = torch.from_numpy(X)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "test_ds = SleepDataset(test_series.series_id.unique(), test_series)\n",
    "\n",
    "del test_series\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f783ff",
   "metadata": {
    "papermill": {
     "duration": 0.0067,
     "end_time": "2023-11-18T05:20:09.156692",
     "exception": false,
     "start_time": "2023-11-18T05:20:09.149992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b417c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T05:20:09.172709Z",
     "iopub.status.busy": "2023-11-18T05:20:09.172237Z",
     "iopub.status.idle": "2023-11-18T05:20:09.191154Z",
     "shell.execute_reply": "2023-11-18T05:20:09.189854Z"
    },
    "papermill": {
     "duration": 0.02995,
     "end_time": "2023-11-18T05:20:09.193655",
     "exception": false,
     "start_time": "2023-11-18T05:20:09.163705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBiGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    残差接続を行う双方向GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, n_layers=1, bidir=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        dir_factor = 2 if bidir else 1\n",
    "        \n",
    "        # @see: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            bias=True, # use bias weights\n",
    "            batch_first=True, # (seq, batch,feature)を(batch, seq, feature)へ\n",
    "            dropout=0,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=hidden_size*dir_factor,\n",
    "            out_features=hidden_size*dir_factor*2,\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(normalized_shape=hidden_size*dir_factor*2)\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=hidden_size*dir_factor*2,\n",
    "            out_features=hidden_size,\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(normalized_shape=hidden_size)\n",
    "        \n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\"順伝播\"\"\"\n",
    "        output, new_h = self.gru(x, h)\n",
    "        \n",
    "        output = self.fc1(output)\n",
    "        output = self.ln1(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output = self.fc2(output)\n",
    "        output = self.ln2(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # skip connection\n",
    "        output = output + x\n",
    "        \n",
    "        return output, new_h\n",
    "        \n",
    "class MultiResidualBiGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    ResidulaBiGRUをn_layers分だけ重ねる\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, out_size, n_layers, bidir=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.fc_in = nn.Linear(\n",
    "            in_features=input_size,\n",
    "            out_features=hidden_size,\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(normalized_shape=hidden_size)\n",
    "        self.bigrus = nn.ModuleList(\n",
    "            [\n",
    "                ResidualBiGRU(\n",
    "                    hidden_size=hidden_size,\n",
    "                    n_layers=1,\n",
    "                    bidir=bidir,\n",
    "                )\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(\n",
    "            in_features=hidden_size,\n",
    "            out_features=out_size,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\"順伝播\"\"\"\n",
    "        if h is None:\n",
    "            # (re)initialize the hidden state\n",
    "            h = [None for _ in range(self.n_layers)]\n",
    "            \n",
    "        x = self.fc_in(x)\n",
    "        x = self.ln(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        new_h = []\n",
    "        for i, bigru in enumerate(self.bigrus):\n",
    "            x, new_hi = bigru(x, h[i])\n",
    "            new_h.append(new_hi)\n",
    "            \n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x, new_h # log probabilities + hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4382577a",
   "metadata": {
    "papermill": {
     "duration": 0.0067,
     "end_time": "2023-11-18T05:20:09.207342",
     "exception": false,
     "start_time": "2023-11-18T05:20:09.200642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8da12b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T05:20:09.222864Z",
     "iopub.status.busy": "2023-11-18T05:20:09.222452Z",
     "iopub.status.idle": "2023-11-18T05:20:09.227127Z",
     "shell.execute_reply": "2023-11-18T05:20:09.226049Z"
    },
    "papermill": {
     "duration": 0.01526,
     "end_time": "2023-11-18T05:20:09.229418",
     "exception": false,
     "start_time": "2023-11-18T05:20:09.214158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_chunk_size = 24*60*100\n",
    "min_interval = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0b0c7a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T05:20:09.245390Z",
     "iopub.status.busy": "2023-11-18T05:20:09.244987Z",
     "iopub.status.idle": "2023-11-18T05:20:11.069623Z",
     "shell.execute_reply": "2023-11-18T05:20:11.068479Z"
    },
    "papermill": {
     "duration": 1.835999,
     "end_time": "2023-11-18T05:20:11.072349",
     "exception": false,
     "start_time": "2023-11-18T05:20:09.236350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MultiResidualBiGRU(\n",
    "    input_size=10,\n",
    "    hidden_size=64,\n",
    "    out_size=2,\n",
    "    n_layers=5,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"/kaggle/input/cmi-deep-sleep-states-train/model_best.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "submission = pd.DataFrame()\n",
    "for i in range(len(test_ds)):\n",
    "    X = test_ds[i].half().to(device)\n",
    "    \n",
    "    seq_len = X.shape[0]\n",
    "    h = None\n",
    "    pred = torch.zeros((len(X), 2)).half()\n",
    "    for j in range(0, seq_len, max_chunk_size):\n",
    "        y_pred, h = model(X[j: j+max_chunk_size].float(), h)\n",
    "        h = [hi.detach() for hi in h]\n",
    "        pred[j: j+max_chunk_size] = y_pred.detach()\n",
    "        \n",
    "        del y_pred\n",
    "        gc.collect()\n",
    "        \n",
    "    del h, X\n",
    "    gc.collect()\n",
    "    \n",
    "    pred = pred.numpy()\n",
    "    \n",
    "    series_id = ids[i]\n",
    "    days = len(pred)/(17280/12)\n",
    "    scores0 = np.zeros(len(pred), dtype=np.float16)\n",
    "    scores1 = np.zeros(len(pred), dtype=np.float16)\n",
    "    \n",
    "    for idx in range(len(pred)):\n",
    "        if pred[idx, 0] == max(pred[max(0, idx-min_interval): idx+min_interval, 0]):\n",
    "            scores0[idx] = max(pred[max(0, idx-min_interval): idx+min_interval, 0])\n",
    "        if pred[idx, 1] == max(pred[max(0, idx-min_interval): idx+min_interval, 1]):\n",
    "            scores1[idx] = max(pred[max(0, idx-min_interval): idx+min_interval, 1])\n",
    "            \n",
    "    candidates_onset = np.argsort(scores0)[-max(1, round(days)):]\n",
    "    candidates_wakeup = np.argsort(scores1)[-max(1, round(days)):]\n",
    "    \n",
    "    # onset\n",
    "    onset = test_ds.data[i][[\"step\"]].iloc[\n",
    "        np.clip(\n",
    "            a=candidates_onset*12,\n",
    "            a_min=0,\n",
    "            a_max=len(test_ds.data[i])-1,\n",
    "        )\n",
    "    ].astype(np.int32)\n",
    "    onset[\"event\"] = \"onset\"\n",
    "    onset[\"series_id\"] = series_id\n",
    "    onset[\"score\"] = scores0[candidates_onset]\n",
    "    \n",
    "    # wakeup\n",
    "    wakeup = test_ds.data[i][[\"step\"]].iloc[\n",
    "        np.clip(\n",
    "            a=candidates_wakeup*12,\n",
    "            a_min=0,\n",
    "            a_max=len(test_ds.data[i])-1,\n",
    "        )\n",
    "    ].astype(np.int32)\n",
    "    wakeup[\"event\"] = \"wakeup\"\n",
    "    wakeup[\"series_id\"] = series_id\n",
    "    wakeup[\"score\"] = scores1[candidates_wakeup]\n",
    "    \n",
    "    submission = pd.concat([submission, onset, wakeup], axis=0)\n",
    "    \n",
    "    del onset, wakeup, candidates_onset, candidates_wakeup, scores0, scores1, pred, series_id\n",
    "    gc.collect()\n",
    "    \n",
    "submission = submission.sort_values([\"series_id\", \"step\"]).reset_index(drop=True)\n",
    "submission[\"row_id\"] = submission.index.astype(int)\n",
    "submission[\"score\"] = submission[\"score\"].fillna(submission[\"score\"].mean())\n",
    "\n",
    "submission = submission[[\"row_id\", \"series_id\", \"step\", \"event\", \"score\"]]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df19ac55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T05:20:11.088209Z",
     "iopub.status.busy": "2023-11-18T05:20:11.087816Z",
     "iopub.status.idle": "2023-11-18T05:20:11.103748Z",
     "shell.execute_reply": "2023-11-18T05:20:11.102633Z"
    },
    "papermill": {
     "duration": 0.026696,
     "end_time": "2023-11-18T05:20:11.106080",
     "exception": false,
     "start_time": "2023-11-18T05:20:11.079384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>0</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.137085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>24</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.188477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>48</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.003283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>144</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.438232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     series_id  step   event     score\n",
       "0       0  038441c925bb     0   onset  0.137085\n",
       "1       1  038441c925bb   144  wakeup  0.000000\n",
       "2       2  03d92c9f6f8a    24   onset  0.188477\n",
       "3       3  03d92c9f6f8a   144  wakeup  0.000000\n",
       "4       4  0402a003dae9    48  wakeup  0.003283\n",
       "5       5  0402a003dae9   144   onset  0.438232"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d433a5",
   "metadata": {
    "papermill": {
     "duration": 0.006817,
     "end_time": "2023-11-18T05:20:11.119947",
     "exception": false,
     "start_time": "2023-11-18T05:20:11.113130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6589269,
     "sourceId": 53666,
     "sourceType": "competition"
    },
    {
     "datasetId": 4019633,
     "sourceId": 6993426,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30579,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.463673,
   "end_time": "2023-11-18T05:20:12.451736",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-18T05:19:55.988063",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "079020f0051c446982f44d03abab5d88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e65af446f4c941879fc3fa7d72e64d55",
       "placeholder": "​",
       "style": "IPY_MODEL_6569281f95f24aefa2a709a7539b19e7",
       "value": "100%"
      }
     },
     "488e7f1302854a339f808343c8604615": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_079020f0051c446982f44d03abab5d88",
        "IPY_MODEL_64b07b064e224c2fbf0e95d9f1873cfd",
        "IPY_MODEL_71ed31284dfc40d8b518c77d38ee83d5"
       ],
       "layout": "IPY_MODEL_6d06a28d96c54cac91124b015d47f106"
      }
     },
     "64b07b064e224c2fbf0e95d9f1873cfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a88028d7532a4b0da565569d79746906",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_98ef68dc996449a49c7d6718af7681ce",
       "value": 3.0
      }
     },
     "6569281f95f24aefa2a709a7539b19e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6d06a28d96c54cac91124b015d47f106": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70e0a8de5a65495c80224a3546042127": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "71ed31284dfc40d8b518c77d38ee83d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cdc64da92bf140578b240d9d2028a181",
       "placeholder": "​",
       "style": "IPY_MODEL_70e0a8de5a65495c80224a3546042127",
       "value": " 3/3 [00:00&lt;00:00, 126.59it/s]"
      }
     },
     "98ef68dc996449a49c7d6718af7681ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a88028d7532a4b0da565569d79746906": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cdc64da92bf140578b240d9d2028a181": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e65af446f4c941879fc3fa7d72e64d55": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
