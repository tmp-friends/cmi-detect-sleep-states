{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2987578d",
   "metadata": {
    "papermill": {
     "duration": 0.005386,
     "end_time": "2023-11-19T07:51:41.278737",
     "exception": false,
     "start_time": "2023-11-19T07:51:41.273351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CMI Detect Sleep States - Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86bd687a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-19T07:51:41.290479Z",
     "iopub.status.busy": "2023-11-19T07:51:41.290072Z",
     "iopub.status.idle": "2023-11-19T07:51:42.038522Z",
     "shell.execute_reply": "2023-11-19T07:51:42.037284Z"
    },
    "papermill": {
     "duration": 0.756967,
     "end_time": "2023-11-19T07:51:42.040825",
     "exception": false,
     "start_time": "2023-11-19T07:51:41.283858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cmi-deep-sleep-states-train/model_best.pth\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2596ea2",
   "metadata": {
    "papermill": {
     "duration": 0.004641,
     "end_time": "2023-11-19T07:51:42.050562",
     "exception": false,
     "start_time": "2023-11-19T07:51:42.045921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08da2f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T07:51:42.062472Z",
     "iopub.status.busy": "2023-11-19T07:51:42.061690Z",
     "iopub.status.idle": "2023-11-19T07:51:48.346150Z",
     "shell.execute_reply": "2023-11-19T07:51:48.345286Z"
    },
    "papermill": {
     "duration": 6.292885,
     "end_time": "2023-11-19T07:51:48.348595",
     "exception": false,
     "start_time": "2023-11-19T07:51:42.055710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import math\n",
    "from math import pi, sqrt, exp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "import sklearn, sklearn.model_selection\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa\n",
    "import ctypes\n",
    "\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6fd5bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T07:51:48.360530Z",
     "iopub.status.busy": "2023-11-19T07:51:48.360201Z",
     "iopub.status.idle": "2023-11-19T07:51:48.365084Z",
     "shell.execute_reply": "2023-11-19T07:51:48.364275Z"
    },
    "papermill": {
     "duration": 0.012955,
     "end_time": "2023-11-19T07:51:48.367226",
     "exception": false,
     "start_time": "2023-11-19T07:51:48.354271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PATHS:\n",
    "    MAIN_DIR = \"/kaggle/input/child-mind-institute-detect-sleep-states/\"\n",
    "    # csv files :\n",
    "    SUBMISSION = MAIN_DIR + \"sample_submission.csv\"\n",
    "    TRAIN_EVENTS = MAIN_DIR + \"train_events.csv\"\n",
    "    \n",
    "    # parquet files:\n",
    "    TRAIN_SERIES = MAIN_DIR + \"train_series.parquet\"\n",
    "    TEST_SERIES = MAIN_DIR + \"test_series.parquet\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59731541",
   "metadata": {
    "papermill": {
     "duration": 0.004765,
     "end_time": "2023-11-19T07:51:48.377594",
     "exception": false,
     "start_time": "2023-11-19T07:51:48.372829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8601e21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T07:51:48.389526Z",
     "iopub.status.busy": "2023-11-19T07:51:48.389109Z",
     "iopub.status.idle": "2023-11-19T07:51:48.412088Z",
     "shell.execute_reply": "2023-11-19T07:51:48.411065Z"
    },
    "papermill": {
     "duration": 0.03164,
     "end_time": "2023-11-19T07:51:48.414208",
     "exception": false,
     "start_time": "2023-11-19T07:51:48.382568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataReader:\n",
    "    def __init__(self, demo_mode):\n",
    "        super().__init__()\n",
    "        \n",
    "        # mapping for data loading\n",
    "        self.names_mapping = {\n",
    "            \"submission\": {\n",
    "                \"path\": PATHS.SUBMISSION,\n",
    "                \"is_parquet\": False,\n",
    "                \"has_timestamp\": False,\n",
    "            },\n",
    "            \"train_events\": {\n",
    "                \"path\": PATHS.TRAIN_EVENTS,\n",
    "                \"is_parquet\": False,\n",
    "                \"has_timestamp\": True,\n",
    "            },\n",
    "            \"train_series\": {\n",
    "                \"path\": PATHS.TRAIN_SERIES,\n",
    "                \"is_parquet\": True,\n",
    "                \"has_timestamp\": True,\n",
    "            },\n",
    "            \"test_series\": {\n",
    "                \"path\": PATHS.TEST_SERIES,\n",
    "                \"is_parquet\": True,\n",
    "                \"has_timestamp\": True,\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        self.valid_names = [\n",
    "            \"submission\",\n",
    "            \"train_events\",\n",
    "            \"train_series\",\n",
    "            \"test_series\",\n",
    "        ]\n",
    "        \n",
    "        self.demo_mode = demo_mode\n",
    "    \n",
    "    def verify(self, data_name):\n",
    "        \"\"\"変数名のバリデーション\"\"\"\n",
    "        if data_name not in self.valid_names:\n",
    "            print(\"PLEASE ENTER A VALID DATASET NAME, VALID NAMES ARE: \", valid_names)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def cleaning(self, data):\n",
    "        \"\"\"drop na values\"\"\"\n",
    "        before_cleaning = len(data)\n",
    "        print(\"Number of missing timestamps: \", len(data[data[\"timestamp\"].isna()]))\n",
    "        \n",
    "        data = data.dropna(subset=[\"timestamp\"])\n",
    "        after_cleaning = len(data)\n",
    "        \n",
    "        print(\n",
    "            \"Percentage of removed rows: {:.1f}%\".format(\n",
    "                100*(before_cleaning - after_cleaning) / before_cleaning\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def reduce_memory_usage(data):\n",
    "        \"\"\"iterate through all the columns of a dataframe and modify the data type to reduce memory usage\"\"\"\n",
    "        start_mem = data.memory_usage().sum() / 1024**2\n",
    "        print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "        \n",
    "        for col in data.columns:\n",
    "            col_type = data[col].dtype\n",
    "            if col_type != object:\n",
    "                c_min = data[col].min()\n",
    "                c_max = data[col].max()\n",
    "                \n",
    "                # 型によってメモリサイズを最適化\n",
    "                if str(col_type)[:3] == \"int\":\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        data[col] = data[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        data[col] = data[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        data[col] = data[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        data[col] = data[col].astype(np.int64)\n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        data[col] = data[col].astype(np.float16)\n",
    "                    elif c_min > np.iinfo(np.float32).min and c_max < np.iinfo(np.float32).max:\n",
    "                        data[col] = data[col].astype(np.float32)\n",
    "                    else:\n",
    "                        data[col] = data[col].astype(np.float64)\n",
    "            else:\n",
    "                data[col] = data[col].astype(\"category\")\n",
    "        \n",
    "        end_mem = data.memory_usage().sum() / 1024**2\n",
    "        \n",
    "        print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "        print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def load_data(self, data_name):\n",
    "        \"\"\"データのロード\"\"\"\n",
    "        self.verify(data_name)\n",
    "        data_props = self.names_mapping[data_name]\n",
    "        \n",
    "        if data_props[\"is_parquet\"]:\n",
    "            if self.demo_mode:\n",
    "                pf = ParquetFile(data_props[\"path\"])\n",
    "                demo_rows = next(pf.iter_batches(batch_size=20_000))\n",
    "                data = pa.Table.from_batches([demo_rows]).to_pandas()\n",
    "            else:\n",
    "                data = pd.read_parquet(data_props[\"path\"])\n",
    "        else:\n",
    "            if self.demo_mode:\n",
    "                data = pd.read_csv(data_props[\"path\"], nrows=20_000)\n",
    "            else:\n",
    "                data = pd.read_csv(data_props[\"path\"])\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        if data_props[\"has_timestamp\"]:\n",
    "            print(\"cleaning\")\n",
    "            data = self.cleaning(data)\n",
    "            \n",
    "            gc.collect()\n",
    "        \n",
    "        data = self.reduce_memory_usage(data)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bad0689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T07:51:48.426238Z",
     "iopub.status.busy": "2023-11-19T07:51:48.425855Z",
     "iopub.status.idle": "2023-11-19T07:51:49.031542Z",
     "shell.execute_reply": "2023-11-19T07:51:49.030462Z"
    },
    "papermill": {
     "duration": 0.614273,
     "end_time": "2023-11-19T07:51:49.033695",
     "exception": false,
     "start_time": "2023-11-19T07:51:48.419422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning\n",
      "Number of missing timestamps:  0\n",
      "Percentage of removed rows: 0.0%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by -92.2%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = DataReader(demo_mode=False)\n",
    "test_series = reader.load_data(data_name=\"test_series\")\n",
    "ids = test_series.series_id.unique()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac1095e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T07:51:49.046424Z",
     "iopub.status.busy": "2023-11-19T07:51:49.046043Z",
     "iopub.status.idle": "2023-11-19T07:51:49.246363Z",
     "shell.execute_reply": "2023-11-19T07:51:49.245425Z"
    },
    "papermill": {
     "duration": 0.209381,
     "end_time": "2023-11-19T07:51:49.248370",
     "exception": false,
     "start_time": "2023-11-19T07:51:49.038989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945fb11767884fa2ac10f262a3e0f3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIGMA = 720\n",
    "SAMPLE_FREQ = 12\n",
    "\n",
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, series_ids, series):\n",
    "        series = series.reset_index()\n",
    "        self.data = []\n",
    "        \n",
    "        for viz_id in tqdm(series_ids):\n",
    "            self.data.append(series.loc[(series.series_id==viz_id)].copy().reset_index())\n",
    "    \n",
    "    def downsample_seq_generate_features(self, feat, downsample_factor=SAMPLE_FREQ):\n",
    "        if len(feat) % SAMPLE_FREQ != 0:\n",
    "            feat = np.concatenate([feat, np.zeros(SAMPLE_FREQ - len(feat) % SAMPLE_FREQ)+feat[-1]])\n",
    "        \n",
    "        # generate seq\n",
    "        feat = np.reshape(feat, (-1, SAMPLE_FREQ))\n",
    "        feat_mean = np.mean(feat, 1)\n",
    "        feat_std = np.std(feat, 1)\n",
    "        feat_median = np.median(feat, 1)\n",
    "        feat_max = np.max(feat, 1)\n",
    "        feat_min = np.min(feat, 1)\n",
    "        \n",
    "        return np.dstack([feat_mean, feat_std, feat_median, feat_max, feat_min])[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx][[\"anglez\", \"enmo\"]].values.astype(np.float32)\n",
    "        \n",
    "        X = np.concatenate(\n",
    "            [\n",
    "                self.downsample_seq_generate_features(\n",
    "                    X[:,i],\n",
    "                    SAMPLE_FREQ,\n",
    "                ) for i in range(X.shape[1])\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        \n",
    "        X = torch.from_numpy(X)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "test_ds = SleepDataset(test_series.series_id.unique(), test_series)\n",
    "\n",
    "del test_series\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59a9dc",
   "metadata": {
    "papermill": {
     "duration": 0.005374,
     "end_time": "2023-11-19T07:51:49.259517",
     "exception": false,
     "start_time": "2023-11-19T07:51:49.254143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b9578be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T07:51:49.272347Z",
     "iopub.status.busy": "2023-11-19T07:51:49.271954Z",
     "iopub.status.idle": "2023-11-19T07:51:49.288135Z",
     "shell.execute_reply": "2023-11-19T07:51:49.287315Z"
    },
    "papermill": {
     "duration": 0.025037,
     "end_time": "2023-11-19T07:51:49.290145",
     "exception": false,
     "start_time": "2023-11-19T07:51:49.265108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBiGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    残差接続を行う双方向GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, n_layers=1, bidir=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        dir_factor = 2 if bidir else 1\n",
    "        \n",
    "        # @see: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            bias=True, # use bias weights\n",
    "            batch_first=True, # (seq, batch,feature)を(batch, seq, feature)へ\n",
    "            dropout=0,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=hidden_size*dir_factor,\n",
    "            out_features=hidden_size*dir_factor*2,\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(normalized_shape=hidden_size*dir_factor*2)\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=hidden_size*dir_factor*2,\n",
    "            out_features=hidden_size,\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(normalized_shape=hidden_size)\n",
    "        \n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\"順伝播\"\"\"\n",
    "        output, new_h = self.gru(x, h)\n",
    "        \n",
    "        output = self.fc1(output)\n",
    "        output = self.ln1(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output = self.fc2(output)\n",
    "        output = self.ln2(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # skip connection\n",
    "        output = output + x\n",
    "        \n",
    "        return output, new_h\n",
    "        \n",
    "class MultiResidualBiGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    ResidulaBiGRUをn_layers分だけ重ねる\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, out_size, n_layers, bidir=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.fc_in = nn.Linear(\n",
    "            in_features=input_size,\n",
    "            out_features=hidden_size,\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(normalized_shape=hidden_size)\n",
    "        self.bigrus = nn.ModuleList(\n",
    "            [\n",
    "                ResidualBiGRU(\n",
    "                    hidden_size=hidden_size,\n",
    "                    n_layers=1,\n",
    "                    bidir=bidir,\n",
    "                )\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(\n",
    "            in_features=hidden_size,\n",
    "            out_features=out_size,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\"順伝播\"\"\"\n",
    "        if h is None:\n",
    "            # (re)initialize the hidden state\n",
    "            h = [None for _ in range(self.n_layers)]\n",
    "            \n",
    "        x = self.fc_in(x)\n",
    "        x = self.ln(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        new_h = []\n",
    "        for i, bigru in enumerate(self.bigrus):\n",
    "            x, new_hi = bigru(x, h[i])\n",
    "            new_h.append(new_hi)\n",
    "            \n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x, new_h # log probabilities + hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bb3b3",
   "metadata": {
    "papermill": {
     "duration": 0.005314,
     "end_time": "2023-11-19T07:51:49.301259",
     "exception": false,
     "start_time": "2023-11-19T07:51:49.295945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5291ed22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T07:51:49.313642Z",
     "iopub.status.busy": "2023-11-19T07:51:49.313250Z",
     "iopub.status.idle": "2023-11-19T07:51:49.317837Z",
     "shell.execute_reply": "2023-11-19T07:51:49.316955Z"
    },
    "papermill": {
     "duration": 0.013177,
     "end_time": "2023-11-19T07:51:49.319836",
     "exception": false,
     "start_time": "2023-11-19T07:51:49.306659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_chunk_size = 24*60*100\n",
    "min_interval = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4edb9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T07:51:49.333220Z",
     "iopub.status.busy": "2023-11-19T07:51:49.332357Z",
     "iopub.status.idle": "2023-11-19T07:51:55.842214Z",
     "shell.execute_reply": "2023-11-19T07:51:55.841373Z"
    },
    "papermill": {
     "duration": 6.519099,
     "end_time": "2023-11-19T07:51:55.844685",
     "exception": false,
     "start_time": "2023-11-19T07:51:49.325586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MultiResidualBiGRU(\n",
    "    input_size=10,\n",
    "    hidden_size=64,\n",
    "    out_size=2,\n",
    "    n_layers=5,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/cmi-deep-sleep-states-train/model_best.pth\"))\n",
    "\n",
    "model.eval()\n",
    "submission = pd.DataFrame()\n",
    "for i in range(len(test_ds)):\n",
    "    X = test_ds[i].half().to(device)\n",
    "    \n",
    "    seq_len = X.shape[0]\n",
    "    h = None\n",
    "    pred = torch.zeros((len(X), 2)).half()\n",
    "    for j in range(0, seq_len, max_chunk_size):\n",
    "        y_pred, h = model(X[j: j+max_chunk_size].float(), h)\n",
    "        h = [hi.detach() for hi in h]\n",
    "        pred[j: j+max_chunk_size] = y_pred.detach()\n",
    "        \n",
    "        del y_pred\n",
    "        gc.collect()\n",
    "        \n",
    "    del h, X\n",
    "    gc.collect()\n",
    "    \n",
    "    pred = pred.numpy()\n",
    "    \n",
    "    series_id = ids[i]\n",
    "    days = len(pred)/(17280/12)\n",
    "    scores0 = np.zeros(len(pred), dtype=np.float16)\n",
    "    scores1 = np.zeros(len(pred), dtype=np.float16)\n",
    "    \n",
    "    for idx in range(len(pred)):\n",
    "        if pred[idx, 0] == max(pred[max(0, idx-min_interval): idx+min_interval, 0]):\n",
    "            scores0[idx] = max(pred[max(0, idx-min_interval): idx+min_interval, 0])\n",
    "        if pred[idx, 1] == max(pred[max(0, idx-min_interval): idx+min_interval, 1]):\n",
    "            scores1[idx] = max(pred[max(0, idx-min_interval): idx+min_interval, 1])\n",
    "            \n",
    "    candidates_onset = np.argsort(scores0)[-max(1, round(days)):]\n",
    "    candidates_wakeup = np.argsort(scores1)[-max(1, round(days)):]\n",
    "    \n",
    "    # onset\n",
    "    onset = test_ds.data[i][[\"step\"]].iloc[\n",
    "        np.clip(\n",
    "            a=candidates_onset*12,\n",
    "            a_min=0,\n",
    "            a_max=len(test_ds.data[i])-1,\n",
    "        )\n",
    "    ].astype(np.int32)\n",
    "    onset[\"event\"] = \"onset\"\n",
    "    onset[\"series_id\"] = series_id\n",
    "    onset[\"score\"] = scores0[candidates_onset]\n",
    "    \n",
    "    # wakeup\n",
    "    wakeup = test_ds.data[i][[\"step\"]].iloc[\n",
    "        np.clip(\n",
    "            a=candidates_wakeup*12,\n",
    "            a_min=0,\n",
    "            a_max=len(test_ds.data[i])-1,\n",
    "        )\n",
    "    ].astype(np.int32)\n",
    "    wakeup[\"event\"] = \"wakeup\"\n",
    "    wakeup[\"series_id\"] = series_id\n",
    "    wakeup[\"score\"] = scores1[candidates_wakeup]\n",
    "    \n",
    "    submission = pd.concat([submission, onset, wakeup], axis=0)\n",
    "    \n",
    "    del onset, wakeup, candidates_onset, candidates_wakeup, scores0, scores1, pred, series_id\n",
    "    gc.collect()\n",
    "    \n",
    "submission = submission.sort_values([\"series_id\", \"step\"]).reset_index(drop=True)\n",
    "submission[\"row_id\"] = submission.index.astype(int)\n",
    "submission[\"score\"] = submission[\"score\"].fillna(submission[\"score\"].mean())\n",
    "\n",
    "submission = submission[[\"row_id\", \"series_id\", \"step\", \"event\", \"score\"]]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fdbcc5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T07:51:55.858031Z",
     "iopub.status.busy": "2023-11-19T07:51:55.857172Z",
     "iopub.status.idle": "2023-11-19T07:51:55.871218Z",
     "shell.execute_reply": "2023-11-19T07:51:55.870260Z"
    },
    "papermill": {
     "duration": 0.023385,
     "end_time": "2023-11-19T07:51:55.873749",
     "exception": false,
     "start_time": "2023-11-19T07:51:55.850364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>0</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.137085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>24</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.188477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>48</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.003283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>144</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.438232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     series_id  step   event     score\n",
       "0       0  038441c925bb     0   onset  0.137085\n",
       "1       1  038441c925bb   144  wakeup  0.000000\n",
       "2       2  03d92c9f6f8a    24   onset  0.188477\n",
       "3       3  03d92c9f6f8a   144  wakeup  0.000000\n",
       "4       4  0402a003dae9    48  wakeup  0.003283\n",
       "5       5  0402a003dae9   144   onset  0.438232"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6589269,
     "sourceId": 53666,
     "sourceType": "competition"
    },
    {
     "datasetId": 4019633,
     "sourceId": 6993426,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.561903,
   "end_time": "2023-11-19T07:51:58.359412",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-19T07:51:37.797509",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03e0fab5a2ef4abba5e34f182a1c6f0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bc7a6f7ef1f5457585889aa396c385e3",
       "placeholder": "​",
       "style": "IPY_MODEL_118d2fb451d24426a3ad74aa8dc88b0e",
       "value": " 3/3 [00:00&lt;00:00, 164.58it/s]"
      }
     },
     "118d2fb451d24426a3ad74aa8dc88b0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "131d058d7ef74ce18173574a59bb5dfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_42b387b6f3ba48829b259c8acffeaf6b",
       "placeholder": "​",
       "style": "IPY_MODEL_487d8d7c8bcd4b3f886e2c1f878a2ca9",
       "value": "100%"
      }
     },
     "42b387b6f3ba48829b259c8acffeaf6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "487d8d7c8bcd4b3f886e2c1f878a2ca9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80c423197ae047c8ae617ee2af03c23c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "945fb11767884fa2ac10f262a3e0f3dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_131d058d7ef74ce18173574a59bb5dfd",
        "IPY_MODEL_c006dcecebdb4e94bea77a46f4c3fd38",
        "IPY_MODEL_03e0fab5a2ef4abba5e34f182a1c6f0a"
       ],
       "layout": "IPY_MODEL_c83eac6d2c554d3f9f45a129b3867028"
      }
     },
     "9e81229efc55429ca06cf5e00b283ac1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc7a6f7ef1f5457585889aa396c385e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c006dcecebdb4e94bea77a46f4c3fd38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e81229efc55429ca06cf5e00b283ac1",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_80c423197ae047c8ae617ee2af03c23c",
       "value": 3.0
      }
     },
     "c83eac6d2c554d3f9f45a129b3867028": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
