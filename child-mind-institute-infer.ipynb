{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68239284",
   "metadata": {
    "papermill": {
     "duration": 0.006481,
     "end_time": "2023-11-12T04:39:24.016255",
     "exception": false,
     "start_time": "2023-11-12T04:39:24.009774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CMI Detect Sleep States - Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c739865",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-12T04:39:24.030807Z",
     "iopub.status.busy": "2023-11-12T04:39:24.030369Z",
     "iopub.status.idle": "2023-11-12T04:39:24.469087Z",
     "shell.execute_reply": "2023-11-12T04:39:24.467400Z"
    },
    "papermill": {
     "duration": 0.449268,
     "end_time": "2023-11-12T04:39:24.471826",
     "exception": false,
     "start_time": "2023-11-12T04:39:24.022558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/child-mind-institute-train/model_best.pth\n",
      "/kaggle/input/child-mind-institute-train/__results__.html\n",
      "/kaggle/input/child-mind-institute-train/__notebook__.ipynb\n",
      "/kaggle/input/child-mind-institute-train/__output__.json\n",
      "/kaggle/input/child-mind-institute-train/custom.css\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d6104",
   "metadata": {
    "papermill": {
     "duration": 0.00582,
     "end_time": "2023-11-12T04:39:24.483936",
     "exception": false,
     "start_time": "2023-11-12T04:39:24.478116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd9c591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:39:24.498800Z",
     "iopub.status.busy": "2023-11-12T04:39:24.498256Z",
     "iopub.status.idle": "2023-11-12T04:39:32.235832Z",
     "shell.execute_reply": "2023-11-12T04:39:32.234886Z"
    },
    "papermill": {
     "duration": 7.748063,
     "end_time": "2023-11-12T04:39:32.238535",
     "exception": false,
     "start_time": "2023-11-12T04:39:24.490472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import math\n",
    "from math import pi, sqrt, exp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "import sklearn, sklearn.model_selection\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa\n",
    "import ctypes\n",
    "\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a19a1a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:39:32.254977Z",
     "iopub.status.busy": "2023-11-12T04:39:32.253938Z",
     "iopub.status.idle": "2023-11-12T04:39:32.260337Z",
     "shell.execute_reply": "2023-11-12T04:39:32.259378Z"
    },
    "papermill": {
     "duration": 0.01815,
     "end_time": "2023-11-12T04:39:32.263742",
     "exception": false,
     "start_time": "2023-11-12T04:39:32.245592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PATHS:\n",
    "    MAIN_DIR = \"/kaggle/input/child-mind-institute-detect-sleep-states/\"\n",
    "    # csv files :\n",
    "    SUBMISSION = MAIN_DIR + \"sample_submission.csv\"\n",
    "    TRAIN_EVENTS = MAIN_DIR + \"train_events.csv\"\n",
    "    \n",
    "    # parquet files:\n",
    "    TRAIN_SERIES = MAIN_DIR + \"train_series.parquet\"\n",
    "    TEST_SERIES = MAIN_DIR + \"test_series.parquet\"\n",
    "    \n",
    "class CFG:\n",
    "    DEMO_MODE = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36d02b",
   "metadata": {
    "papermill": {
     "duration": 0.00649,
     "end_time": "2023-11-12T04:39:32.277301",
     "exception": false,
     "start_time": "2023-11-12T04:39:32.270811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f76713f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:39:32.292576Z",
     "iopub.status.busy": "2023-11-12T04:39:32.292200Z",
     "iopub.status.idle": "2023-11-12T04:39:32.318913Z",
     "shell.execute_reply": "2023-11-12T04:39:32.317909Z"
    },
    "papermill": {
     "duration": 0.037221,
     "end_time": "2023-11-12T04:39:32.321405",
     "exception": false,
     "start_time": "2023-11-12T04:39:32.284184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataReader:\n",
    "    def __init__(self, demo_mode):\n",
    "        super().__init__()\n",
    "        \n",
    "        # mapping for data loading\n",
    "        self.names_mapping = {\n",
    "            \"submission\": {\n",
    "                \"path\": PATHS.SUBMISSION,\n",
    "                \"is_parquet\": False,\n",
    "                \"has_timestamp\": False,\n",
    "            },\n",
    "            \"train_events\": {\n",
    "                \"path\": PATHS.TRAIN_EVENTS,\n",
    "                \"is_parquet\": False,\n",
    "                \"has_timestamp\": True,\n",
    "            },\n",
    "            \"train_series\": {\n",
    "                \"path\": PATHS.TRAIN_SERIES,\n",
    "                \"is_parquet\": True,\n",
    "                \"has_timestamp\": True,\n",
    "            },\n",
    "            \"test_series\": {\n",
    "                \"path\": PATHS.TEST_SERIES,\n",
    "                \"is_parquet\": True,\n",
    "                \"has_timestamp\": True,\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        self.valid_names = [\n",
    "            \"submission\",\n",
    "            \"train_events\",\n",
    "            \"train_series\",\n",
    "            \"test_series\",\n",
    "        ]\n",
    "        \n",
    "        self.demo_mode = demo_mode\n",
    "    \n",
    "    def verify(self, data_name):\n",
    "        \"\"\"変数名のバリデーション\"\"\"\n",
    "        if data_name not in self.valid_names:\n",
    "            print(\"PLEASE ENTER A VALID DATASET NAME, VALID NAMES ARE: \", valid_names)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def cleaning(self, data):\n",
    "        \"\"\"drop na values\"\"\"\n",
    "        before_cleaning = len(data)\n",
    "        print(\"Number of missing timestamps: \", len(data[data[\"timestamp\"].isna()]))\n",
    "        \n",
    "        data = data.dropna(subset=[\"timestamp\"])\n",
    "        after_cleaning = len(data)\n",
    "        \n",
    "        print(\n",
    "            \"Percentage of removed rows: {:.1f}%\".format(\n",
    "                100*(before_cleaning - after_cleaning) / before_cleaning\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def reduce_memory_usage(data):\n",
    "        \"\"\"iterate through all the columns of a dataframe and modify the data type to reduce memory usage\"\"\"\n",
    "        start_mem = data.memory_usage().sum() / 1024**2\n",
    "        print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "        \n",
    "        for col in data.columns:\n",
    "            col_type = data[col].dtype\n",
    "            if col_type != object:\n",
    "                c_min = data[col].min()\n",
    "                c_max = data[col].max()\n",
    "                \n",
    "                # 型によってメモリサイズを最適化\n",
    "                if str(col_type)[:3] == \"int\":\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        data[col] = data[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        data[col] = data[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        data[col] = data[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        data[col] = data[col].astype(np.int64)\n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        data[col] = data[col].astype(np.float16)\n",
    "                    elif c_min > np.iinfo(np.float32).min and c_max < np.iinfo(np.float32).max:\n",
    "                        data[col] = data[col].astype(np.float32)\n",
    "                    else:\n",
    "                        data[col] = data[col].astype(np.float64)\n",
    "            else:\n",
    "                data[col] = data[col].astype(\"category\")\n",
    "        \n",
    "        end_mem = data.memory_usage().sum() / 1024**2\n",
    "        \n",
    "        print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "        print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def load_data(self, data_name):\n",
    "        \"\"\"データのロード\"\"\"\n",
    "        self.verify(data_name)\n",
    "        data_props = self.names_mapping[data_name]\n",
    "        \n",
    "        if data_props[\"is_parquet\"]:\n",
    "            if self.demo_mode:\n",
    "                pf = ParquetFile(data_props[\"path\"])\n",
    "                demo_rows = next(pf.iter_batches(batch_size=20_000))\n",
    "                data = pa.Table.from_batches([demo_rows]).to_pandas()\n",
    "            else:\n",
    "                data = pd.read_parquet(data_props[\"path\"])\n",
    "        else:\n",
    "            if self.demo_mode:\n",
    "                data = pd.read_csv(data_props[\"path\"], nrows=20_000)\n",
    "            else:\n",
    "                data = pd.read_csv(data_props[\"path\"])\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        if data_props[\"has_timestamp\"]:\n",
    "            print(\"cleaning\")\n",
    "            data = self.cleaning(data)\n",
    "            \n",
    "            gc.collect()\n",
    "        \n",
    "        data = self.reduce_memory_usage(data)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d90ff19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:39:32.336190Z",
     "iopub.status.busy": "2023-11-12T04:39:32.335474Z",
     "iopub.status.idle": "2023-11-12T04:39:33.023043Z",
     "shell.execute_reply": "2023-11-12T04:39:33.021765Z"
    },
    "papermill": {
     "duration": 0.698063,
     "end_time": "2023-11-12T04:39:33.025708",
     "exception": false,
     "start_time": "2023-11-12T04:39:32.327645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning\n",
      "Number of missing timestamps:  0\n",
      "Percentage of removed rows: 0.0%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by -92.2%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = DataReader(demo_mode=False)\n",
    "test_series = reader.load_data(data_name=\"test_series\")\n",
    "ids = test_series.series_id.unique()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2171b7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:39:33.041674Z",
     "iopub.status.busy": "2023-11-12T04:39:33.041261Z",
     "iopub.status.idle": "2023-11-12T04:39:33.262115Z",
     "shell.execute_reply": "2023-11-12T04:39:33.260776Z"
    },
    "papermill": {
     "duration": 0.234652,
     "end_time": "2023-11-12T04:39:33.266824",
     "exception": false,
     "start_time": "2023-11-12T04:39:33.032172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816a1939f6dd47e6825d0157b97ffde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIGMA = 720\n",
    "SAMPLE_FREQ = 12\n",
    "\n",
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, series_ids, series):\n",
    "        series = series.reset_index()\n",
    "        self.data = []\n",
    "        \n",
    "        for viz_id in tqdm(series_ids):\n",
    "            self.data.append(series.loc[(series.series_id==viz_id)].copy().reset_index())\n",
    "    \n",
    "    def downsample_seq_generate_features(self, feat, downsample_factor=SAMPLE_FREQ):\n",
    "        if len(feat) % SAMPLE_FREQ != 0:\n",
    "            feat = np.concatenate([feat, np.zeros(SAMPLE_FREQ - len(feat) % SAMPLE_FREQ)])\n",
    "        \n",
    "        # generate seq\n",
    "        feat = np.reshape(feat, (-1, SAMPLE_FREQ))\n",
    "        feat_mean = np.mean(feat, 1)\n",
    "        feat_std = np.std(feat, 1)\n",
    "        feat_median = np.median(feat, 1)\n",
    "        feat_max = np.max(feat, 1)\n",
    "        feat_min = np.min(feat, 1)\n",
    "        \n",
    "        return np.dstack([feat_mean, feat_std, feat_median, feat_max, feat_min])[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx][[\"anglez\", \"enmo\"]].values.astype(np.float32)\n",
    "        \n",
    "        X = np.concatenate(\n",
    "            [\n",
    "                self.downsample_seq_generate_features(\n",
    "                    X[:,i],\n",
    "                    SAMPLE_FREQ,\n",
    "                ) for i in range(X.shape[1])\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        \n",
    "        X = torch.from_numpy(X)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "test_ds = SleepDataset(test_series.series_id.unique(), test_series)\n",
    "\n",
    "del test_series\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4c400",
   "metadata": {
    "papermill": {
     "duration": 0.006579,
     "end_time": "2023-11-12T04:39:33.280112",
     "exception": false,
     "start_time": "2023-11-12T04:39:33.273533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "042446c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:39:33.296156Z",
     "iopub.status.busy": "2023-11-12T04:39:33.295757Z",
     "iopub.status.idle": "2023-11-12T04:39:33.315404Z",
     "shell.execute_reply": "2023-11-12T04:39:33.314279Z"
    },
    "papermill": {
     "duration": 0.03117,
     "end_time": "2023-11-12T04:39:33.318022",
     "exception": false,
     "start_time": "2023-11-12T04:39:33.286852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBiGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    残差接続を行う双方向GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, n_layers=1, bidir=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        dir_factor = 2 if bidir else 1\n",
    "        \n",
    "        # @see: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            bias=True, # use bias weights\n",
    "            batch_first=True, # (seq, batch,feature)を(batch, seq, feature)へ\n",
    "            dropout=0,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=hidden_size*dir_factor,\n",
    "            out_features=hidden_size*dir_factor*2,\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(normalized_shape=hidden_size*dir_factor*2)\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=hidden_size*dir_factor*2,\n",
    "            out_features=hidden_size,\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(normalized_shape=hidden_size)\n",
    "        \n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\"順伝播\"\"\"\n",
    "        output, new_h = self.gru(x, h)\n",
    "        \n",
    "        output = self.fc1(output)\n",
    "        output = self.ln1(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output = self.fc2(output)\n",
    "        output = self.ln2(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # skip connection\n",
    "        output = output + x\n",
    "        \n",
    "        return output, new_h\n",
    "        \n",
    "class MultiResidualBiGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    ResidulaBiGRUをn_layers分だけ重ねる\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, out_size, n_layers, bidir=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.fc_in = nn.Linear(\n",
    "            in_features=input_size,\n",
    "            out_features=hidden_size,\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(normalized_shape=hidden_size)\n",
    "        self.bigrus = nn.ModuleList(\n",
    "            [\n",
    "                ResidualBiGRU(\n",
    "                    hidden_size=hidden_size,\n",
    "                    n_layers=1,\n",
    "                    bidir=bidir,\n",
    "                )\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(\n",
    "            in_features=hidden_size,\n",
    "            out_features=out_size,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\"順伝播\"\"\"\n",
    "        if h is None:\n",
    "            # (re)initialize the hidden state\n",
    "            h = [None for _ in range(self.n_layers)]\n",
    "            \n",
    "        x = self.fc_in(x)\n",
    "        x = self.ln(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        new_h = []\n",
    "        for i, bigru in enumerate(self.bigrus):\n",
    "            x, new_hi = bigru(x, h[i])\n",
    "            new_h.append(new_hi)\n",
    "            \n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x, new_h # log probabilities + hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb17f4",
   "metadata": {
    "papermill": {
     "duration": 0.006644,
     "end_time": "2023-11-12T04:39:33.331619",
     "exception": false,
     "start_time": "2023-11-12T04:39:33.324975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbbb6cf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:39:33.347665Z",
     "iopub.status.busy": "2023-11-12T04:39:33.346876Z",
     "iopub.status.idle": "2023-11-12T04:39:33.351242Z",
     "shell.execute_reply": "2023-11-12T04:39:33.350459Z"
    },
    "papermill": {
     "duration": 0.015138,
     "end_time": "2023-11-12T04:39:33.353568",
     "exception": false,
     "start_time": "2023-11-12T04:39:33.338430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_chunk_size = 24*60*100\n",
    "min_interval = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c00a87b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:39:33.369906Z",
     "iopub.status.busy": "2023-11-12T04:39:33.369080Z",
     "iopub.status.idle": "2023-11-12T04:39:35.256281Z",
     "shell.execute_reply": "2023-11-12T04:39:35.255042Z"
    },
    "papermill": {
     "duration": 1.899431,
     "end_time": "2023-11-12T04:39:35.259852",
     "exception": false,
     "start_time": "2023-11-12T04:39:33.360421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MultiResidualBiGRU(\n",
    "    input_size=10,\n",
    "    hidden_size=64,\n",
    "    out_size=2,\n",
    "    n_layers=5,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"/kaggle/input/child-mind-institute-train/model_best.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "submission = pd.DataFrame()\n",
    "for i in range(len(test_ds)):\n",
    "    X = test_ds[i].half()\n",
    "    \n",
    "    seq_len = X.shape[0]\n",
    "    h = None\n",
    "    pred = torch.zeros((len(X), 2)).half()\n",
    "    for j in range(0, seq_len, max_chunk_size):\n",
    "        y_pred, h = model(X[j: j+max_chunk_size].float(), h)\n",
    "        h = [hi.detach() for hi in h]\n",
    "        pred[j: j+max_chunk_size] = y_pred.detach()\n",
    "        \n",
    "        del y_pred\n",
    "        gc.collect()\n",
    "        \n",
    "    del h, X\n",
    "    gc.collect()\n",
    "    \n",
    "    pred = pred.numpy()\n",
    "    \n",
    "    series_id = ids[i]\n",
    "    days = len(pred)/(17280/12)\n",
    "    scores0 = np.zeros(len(pred), dtype=np.float16)\n",
    "    scores1 = np.zeros(len(pred), dtype=np.float16)\n",
    "    \n",
    "    for idx in range(len(pred)):\n",
    "        if pred[idx, 0] == max(pred[max(0, idx-min_interval): idx+min_interval, 0]):\n",
    "            scores0[idx] = max(pred[max(0, idx-min_interval): idx+min_interval, 0])\n",
    "        if pred[idx, 1] == max(pred[max(0, idx-min_interval): idx+min_interval, 1]):\n",
    "            scores1[idx] = max(pred[max(0, idx-min_interval): idx+min_interval, 1])\n",
    "            \n",
    "    candidates_onset = np.argsort(scores0)[-max(1, round(days)):]\n",
    "    candidates_wakeup = np.argsort(scores1)[-max(1, round(days)):]\n",
    "    \n",
    "    # onset\n",
    "    onset = test_ds.data[i][[\"step\"]].iloc[\n",
    "        np.clip(\n",
    "            a=candidates_onset*12,\n",
    "            a_min=0,\n",
    "            a_max=len(test_ds.data[i])-1,\n",
    "        )\n",
    "    ].astype(np.int32)\n",
    "    onset[\"event\"] = \"onset\"\n",
    "    onset[\"series_id\"] = series_id\n",
    "    onset[\"score\"] = scores0[candidates_onset]\n",
    "    \n",
    "    # wakeup\n",
    "    wakeup = test_ds.data[i][[\"step\"]].iloc[\n",
    "        np.clip(\n",
    "            a=candidates_wakeup*12,\n",
    "            a_min=0,\n",
    "            a_max=len(test_ds.data[i])-1,\n",
    "        )\n",
    "    ].astype(np.int32)\n",
    "    wakeup[\"event\"] = \"wakeup\"\n",
    "    wakeup[\"series_id\"] = series_id\n",
    "    wakeup[\"score\"] = scores1[candidates_wakeup]\n",
    "    \n",
    "    submission = pd.concat([submission, onset, wakeup], axis=0)\n",
    "    \n",
    "    del onset, wakeup, candidates_onset, candidates_wakeup, scores0, scores1, pred, series_id\n",
    "    gc.collect()\n",
    "    \n",
    "submission = submission.sort_values([\"series_id\", \"step\"]).reset_index(drop=True)\n",
    "submission[\"row_id\"] = submission.index.astype(int)\n",
    "submission[\"score\"] = submission[\"score\"].fillna(submission[\"score\"].mean())\n",
    "\n",
    "submission = submission[[\"row_id\", \"series_id\", \"step\", \"event\", \"score\"]]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67af678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:39:35.282050Z",
     "iopub.status.busy": "2023-11-12T04:39:35.280284Z",
     "iopub.status.idle": "2023-11-12T04:39:35.301617Z",
     "shell.execute_reply": "2023-11-12T04:39:35.300734Z"
    },
    "papermill": {
     "duration": 0.037133,
     "end_time": "2023-11-12T04:39:35.304228",
     "exception": false,
     "start_time": "2023-11-12T04:39:35.267095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>0</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.107788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.162476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>72</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.107727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.150146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>144</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.269287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.233276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     series_id  step   event     score\n",
       "0       0  038441c925bb     0   onset  0.107788\n",
       "1       1  038441c925bb   144  wakeup  0.162476\n",
       "2       2  03d92c9f6f8a    72   onset  0.107727\n",
       "3       3  03d92c9f6f8a   144  wakeup  0.150146\n",
       "4       4  0402a003dae9   144   onset  0.269287\n",
       "5       5  0402a003dae9   144  wakeup  0.233276"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50426556",
   "metadata": {
    "papermill": {
     "duration": 0.006788,
     "end_time": "2023-11-12T04:39:35.319106",
     "exception": false,
     "start_time": "2023-11-12T04:39:35.312318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.285337,
   "end_time": "2023-11-12T04:39:36.752216",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-12T04:39:20.466879",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0aa859fd92dc4ad9837d558601f777e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4946be95c1d34e788f3759fc5e76d0b8",
       "placeholder": "​",
       "style": "IPY_MODEL_789ba9ae86aa4048a6fa54bd78d8554e",
       "value": " 3/3 [00:00&lt;00:00, 122.00it/s]"
      }
     },
     "264f721ddf3b49caadfc00a8e7d811cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "354d7eb1791d4d3889cfea76242f6b2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4946be95c1d34e788f3759fc5e76d0b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "789ba9ae86aa4048a6fa54bd78d8554e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "816a1939f6dd47e6825d0157b97ffde0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dc2b9196af974018bc00d65ea97243ad",
        "IPY_MODEL_c33f8f4930b2460d8ea51241b193bc5d",
        "IPY_MODEL_0aa859fd92dc4ad9837d558601f777e0"
       ],
       "layout": "IPY_MODEL_264f721ddf3b49caadfc00a8e7d811cb"
      }
     },
     "a90796ff3f8c4d0faf37f5e6f363e14c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c33f8f4930b2460d8ea51241b193bc5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cb2399a3013c43b687aec9c0b291b06b",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a90796ff3f8c4d0faf37f5e6f363e14c",
       "value": 3.0
      }
     },
     "c989849f5089446083072cf5dd442bda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cb2399a3013c43b687aec9c0b291b06b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc2b9196af974018bc00d65ea97243ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_354d7eb1791d4d3889cfea76242f6b2f",
       "placeholder": "​",
       "style": "IPY_MODEL_c989849f5089446083072cf5dd442bda",
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
